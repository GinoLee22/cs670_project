{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Restaurants You Will Love**\n",
    "\n",
    "**CSCE 670: Information Retrieval - Spring 2017** \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Pre-Process\n",
    "<h5 style=\"color:red\">You don't have to run this file to do the preprocessing. It's very time-cosuming. All generated files are uploaded to Google Drive.</h5>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Filter out all reviews of restaurants\n",
    "Yelp challenge dataset contains not only reviews of restaurants but also other bussinesses. The first step is thus from Yelp Challenge data 'yelp_academic_dataset_business.json' to filter out all restaurants bussiness_id. Then get all reviews to restaurants to form 'Restaurants_reviews.json' as raw data for this project."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import json, os\n",
    "import re\n",
    "\n",
    "yelp_raw = \"yelp_raw_data/yelp_academic_dataset_business.json\"\n",
    "yelp_review = \"yelp_raw_data/yelp_academic_dataset_review.json\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done!\n"
     ]
    }
   ],
   "source": [
    "All_restaurants = []\n",
    "raw_business = open(yelp_raw, 'r')\n",
    "raw_review = open(yelp_review, 'r')\n",
    "\n",
    "for line in raw_business:\n",
    "    try: \n",
    "        category = json.loads(line)[\"categories\"][0]\n",
    "    except:\n",
    "        continue\n",
    "    if category == 'Restaurants':\n",
    "        All_restaurants.append(json.loads(line)[\"business_id\"])\n",
    "    \n",
    "print All_restaurants.__len__()\n",
    "output = open(\"data/Restaurants_review.json\",'w')\n",
    "\n",
    "for line in raw_review:\n",
    "    try:\n",
    "        business_id = json.loads(line)[\"business_id\"]\n",
    "        if business_id in All_restaurants:\n",
    "             output.write(line)\n",
    "    except:\n",
    "        continue\n",
    "            \n",
    "output.close()\n",
    "print \"Done!\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Refine Data\n",
    "Collaborative Filter and Lantent Factor both cannot handle 'cold start' problems. The sparsity of input matrix can be regarded as cold start and undermine the training step of our project. So we eliminate new joining retautants which have less than 5 reviews yet, and apply this rule to users as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1st part done\n"
     ]
    }
   ],
   "source": [
    "## 1. get the number of users & items in training data\n",
    "# get the size of user_id & business_id\n",
    "user_id = []\n",
    "business_id = []\n",
    "with open('data/Restaurants_review.json') as f:\n",
    "    for line in f:\n",
    "        temp = json.loads(line)        \n",
    "        user_id.append(temp[\"user_id\"])\n",
    "        business_id.append(temp[\"business_id\"])\n",
    "        \n",
    "# This is without duplication: set\n",
    "user_id = set(user_id)\n",
    "business_id = set(business_id)\n",
    "\n",
    "print \"1st part done\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2nd part done\n"
     ]
    }
   ],
   "source": [
    "## 2. add the \"star\" into the dictionary\n",
    "# initialize the dictionary:\n",
    "#   user_bias_list = {user_id --> a list of scores}\n",
    "#   business_bias_list = {business_id --> a list of scores}\n",
    "average = 0\n",
    "num_star = 0\n",
    "user_bias_list = {}\n",
    "business_bias_list = {}\n",
    "for user_key in user_id:\n",
    "    user_bias_list[user_key] = []\n",
    "for business_key in business_id:\n",
    "    business_bias_list[business_key] = []\n",
    "\n",
    "# appending the list\n",
    "with open('data/Restaurants_review.json') as f:\n",
    "    for line in f:\n",
    "        # get the infor from file\n",
    "        temp = json.loads(line)        \n",
    "        cur_user_id = temp[\"user_id\"]\n",
    "        cur_business_id = temp[\"business_id\"]\n",
    "        star = temp[\"stars\"]\n",
    "        # filling the dictionary & calculate the average\n",
    "        user_bias_list[cur_user_id].append(star)\n",
    "        business_bias_list[cur_business_id].append(star)\n",
    "    \n",
    "print \"2nd part done\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3rb part done\n"
     ]
    }
   ],
   "source": [
    "## 3. get the list length of user_bias_list & business_bias_list\n",
    "beyond_num_user = []\n",
    "beyond_num_business = []\n",
    "for key in user_bias_list:\n",
    "    if user_bias_list[key].__len__() > 5:\n",
    "        beyond_num_user.append(key)\n",
    "for key in business_bias_list:\n",
    "    if business_bias_list[key].__len__() > 5:\n",
    "        beyond_num_business.append(key)\n",
    "\n",
    "print \"3rb part done\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Because the 'Restaurants_review.json' has over 80,000 records, the next cell is used to break down the large .json file to several files contain only 3,000 records"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done!\n"
     ]
    }
   ],
   "source": [
    "myfile = open('data/Restaurants_review.json','r')\n",
    "\n",
    "count = 0\n",
    "file_number = 0\n",
    "outfile = open('./temp/final_review' + str(file_number) + '.json','w')\n",
    "for line in myfile:    \n",
    "    count += 1\n",
    "    outfile.write(line)\n",
    "    if count == 3000:\n",
    "        count = 0\n",
    "        file_number += 1\n",
    "        outfile = open('./temp/final_review' + str(file_number) + '.json','w')\n",
    "    \n",
    "print \"Done!\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "final_output = open('data/refined_review.json','a+')\n",
    "\n",
    "i = 0\n",
    "for infile in os.listdir(os.getcwd() + '/temp'):\n",
    "    if infile.endswith(\".json\"):\n",
    "        infile = open('./temp/'+ infile,'r')\n",
    "        \n",
    "        for line in infile:\n",
    "            user = json.loads(line)[\"user_id\"]\n",
    "            business = json.loads(line)[\"business_id\"]\n",
    "    \n",
    "            if user in beyond_num_user and business in beyond_num_business:\n",
    "                outfile.write(line)\n",
    "            \n",
    "        print \"generating \" + str(i) + \" file\"\n",
    "        i += 1\n",
    "        \n",
    "final_output.close()"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
