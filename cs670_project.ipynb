{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from nltk.stem.porter import PorterStemmer\n",
    "import json\n",
    "import re\n",
    "import glob\n",
    "import math\n",
    "from numpy import *\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Pre-Process (Zhong)\n",
    "Delete the users and restaurants with few comments to avoid \"Cold-Start Problem\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Process (Wang)\n",
    "Cluster the pre-processed data using word2vec\n",
    "\n",
    "this is the after merge"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Latent Factors + Bias\n",
    "Using Latent Factor Model + User and Item bias to obtain \"user-concept\" and \"item-concept\" Matrices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16274\n",
      "1428\n",
      "done\n"
     ]
    }
   ],
   "source": [
    "## objectives\n",
    "## 1. get the number of users & items in training data. Entry of matrix\n",
    "\n",
    "## interface:\n",
    "## input(1)\n",
    "#    name of a file\n",
    "## output(2)\n",
    "#    user_id: a list of distinct users\n",
    "#    business_id: a list of distinct restaurant\n",
    "\n",
    "def matrix_entry(file_name):\n",
    "    # get the size of user_id & business_id\n",
    "    user_id = []\n",
    "    business_id = []\n",
    "    with open(file_name) as f:\n",
    "        for line in f:\n",
    "            temp = json.loads(line)        \n",
    "            user_id.append(temp[\"user_id\"])\n",
    "            business_id.append(temp[\"business_id\"])\n",
    "    # This is without duplication: set\n",
    "    user_id = list(set(user_id))\n",
    "    business_id = list(set(business_id))\n",
    "    return [user_id, business_id]\n",
    "\n",
    "# file_name = 'yelp_data/training_at5.json'\n",
    "file_name = 'proj_data/cluster9.json'\n",
    "[user_id, business_id] = matrix_entry(file_name)\n",
    "print user_id.__len__()\n",
    "print business_id.__len__()\n",
    "print \"done\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MUsXhUuDRzGLkh2l3aNDGA\n",
      "bxUZorggwGDpU_liCTZazw\n"
     ]
    }
   ],
   "source": [
    "print user_id[0]\n",
    "print business_id[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n"
     ]
    }
   ],
   "source": [
    "## Objectives\n",
    "## 1. calculate the \"Global Average\" with variable name \"average\"\n",
    "## 2. user bias of all users with variable name \"origin_user_bias\"\n",
    "#     it is a dictionary = {user_id --> user average score}\n",
    "#     intermedia variable: user_bias_list = {user_id --> a list of scores}\n",
    "## 3. restaurant bias of all restaurants with variable name \"origin_restaurant_bias\"\n",
    "#     it is a dictionary = {business_id --> restaurant averate score}\n",
    "#     intermedia variable: business_bias_list = {business_id --> a list of scores}\n",
    "\n",
    "## interface:\n",
    "## input(3:\n",
    "#    name of a file\n",
    "#    user_id\n",
    "#    business_id\n",
    "#\n",
    "## output(3):\n",
    "#    global average\n",
    "#    origin_user_bias\n",
    "#    origin_business_bias\n",
    "def baseline(file_name, user_id, business_id):\n",
    "    average = 0\n",
    "    num_star = 0\n",
    "    user_bias_list = {}\n",
    "    origin_user_bias = {}\n",
    "    business_bias_list = {}\n",
    "    origin_business_bias = {}\n",
    "    for value in user_id:\n",
    "        user_bias_list[value] = []\n",
    "        origin_user_bias[value] = 0\n",
    "    for value in business_id:\n",
    "        business_bias_list[value] = []\n",
    "        origin_business_bias[value] = 0\n",
    "\n",
    "    # adding the list\n",
    "    with open(file_name) as f:\n",
    "        for line in f:\n",
    "            # get the infor from file\n",
    "            temp = json.loads(line)        \n",
    "            cur_user_id = temp[\"user_id\"]\n",
    "            cur_business_id = temp[\"business_id\"]\n",
    "            star = temp[\"stars\"]\n",
    "            # filling the dictionary & calculate the average\n",
    "            average += star\n",
    "            num_star += 1\n",
    "            user_bias_list[cur_user_id].append(star)\n",
    "            business_bias_list[cur_business_id].append(star)\n",
    "\n",
    "    # average\n",
    "    average /= float(num_star)\n",
    "    # calculate: user_bias = {user_id --> average score} & business_bias = {business_id --> average score}\n",
    "    for user_key in user_bias_list:\n",
    "        b_x = sum(user_bias_list[user_key]) / float(user_bias_list[user_key].__len__()) - average\n",
    "        origin_user_bias[user_key] = b_x\n",
    "    for business_key in business_bias_list:\n",
    "        b_i = sum(business_bias_list[business_key]) / float(business_bias_list[business_key].__len__()) - average\n",
    "        origin_business_bias[business_key] = b_i\n",
    "    return [average, origin_user_bias, origin_business_bias]\n",
    "\n",
    "file_name = 'yelp_data/training_at5.json'\n",
    "[average, origin_user_bias, origin_business_bias] = baseline(file_name, user_id, business_id)\n",
    "print \"done\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n"
     ]
    }
   ],
   "source": [
    "## Objective:\n",
    "## 1. Make \"user_id\" and \"business_id\" in the data match the index in latent factor model\n",
    "\n",
    "## interface\n",
    "## input():\n",
    "#    user_id\n",
    "#   business_id\n",
    "## output():\n",
    "#    \n",
    "def matching(user_id, business_id):\n",
    "    # user_id = list(user_id)\n",
    "    user_idx = range(user_id.__len__())\n",
    "    user_match = dict(zip(user_id, user_idx))\n",
    "\n",
    "#     business_id = list(business_id)\n",
    "    business_idx = range(business_id.__len__())\n",
    "    business_match= dict(zip(business_id, business_idx))\n",
    "    return [user_match, business_match]\n",
    "\n",
    "[user_match, business_match] = matching(user_id, business_id)\n",
    "print \"done\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Objective:\n",
    "## 1. Sochastic Gradient Decent training function with bias\n",
    "\n",
    "## SGD training function interface\n",
    "## inputs(10):\n",
    "#    file_name: training file\n",
    "#    ite: number of iteration\n",
    "#    lam: regulation factor: assume lam1 == lam2 == lam3 == lam4\n",
    "#    mu: study rate: assume mu1 = mu2\n",
    "#    k: number of concept in latent factor\n",
    "#    m: number of users\n",
    "#    n: number of items (restaurant)\n",
    "#    user_match: from user_id to index i\n",
    "#    business_match: from business_id to index j\n",
    "#    user_bias & business_bias: should equal to \"original user_bias & business_bias\", whose values won't change\n",
    "#    average: global average\n",
    "## outputs(4):\n",
    "#    latent factor q & p, updated user_bias & business_bias\n",
    "\n",
    "def SGD_train(file_name, ite, lam, mu, k, m, n, user_match, business_match, user_bias, business_bias, average):\n",
    "    # initialization\n",
    "    q = np.random.rand(m, k) * sqrt(5.0 / k)  # normalization\n",
    "    p = np.random.rand(n, k) * sqrt(5.0 / k)\n",
    "    fig = empty(ite)\n",
    "\n",
    "    ## essential steps\n",
    "    # 1. read the file to get user_id, business_id, stars\n",
    "    # 2. find the corresponding index of user_id, business_id in q and p\n",
    "    # 3. Stochastic GD alg\n",
    "    for num in range(0, ite):\n",
    "#         print num\n",
    "        # read the file to update q & p\n",
    "        with open(file_name) as f:\n",
    "            for line in f:\n",
    "                temp = json.loads(line)\n",
    "                cur_user_id = temp[\"user_id\"]\n",
    "                cur_business_id = temp[\"business_id\"]\n",
    "                # get initialized b_x, b_i\n",
    "                b_x = user_bias[cur_user_id]\n",
    "                b_i = business_bias[cur_business_id]\n",
    "                i = user_match[cur_user_id]                  # get the index of corresponding user in q\n",
    "                j = business_match[cur_business_id]          # get the index of corresponding business in p\n",
    "                star = temp[\"stars\"]\n",
    "                # updating p, q, b_x & b_i\n",
    "                eps = 2 * (star - (average + b_x + b_i + dot(q[i, ], p[j, ])))\n",
    "                temp_q = q[i, ] + mu * (eps * p[j, ] - 2 * lam * q[i, ])\n",
    "                temp_p = p[j, ] + mu * (eps * q[i, ] - 2 * lam * p[j, ])\n",
    "                q[i, ] = temp_q\n",
    "                p[j, ] = temp_p\n",
    "                user_bias[cur_user_id] = b_x + mu * (eps - 2 * lam * b_x)\n",
    "                business_bias[cur_business_id] = b_i + mu * (eps - 2 * lam * b_i)\n",
    "    \n",
    "        # read the file to calculate the error\n",
    "#         error = 0\n",
    "#         with open(file_name) as f:\n",
    "#             for line in f:\n",
    "#                 temp = json.loads(line)\n",
    "#                 cur_user_id = temp[\"user_id\"]\n",
    "#                 cur_business_id = temp[\"business_id\"]\n",
    "#                 i = user_match[cur_user_id]\n",
    "#                 j = business_match[cur_business_id]\n",
    "#                 b_x = user_bias[cur_user_id]\n",
    "#                 b_i = business_bias[cur_business_id] \n",
    "#                 star = temp[\"stars\"]\n",
    "#                 error += (star - (average + b_x + b_i + dot(q[i, ], p[j, ]))) ** 2\n",
    "#         # add the regulation error (combine them in all)\n",
    "#         # regulation for b_x & b_i\n",
    "#         regu_user_bias = 0\n",
    "#         regu_business_bias = 0\n",
    "#         for key in user_bias:\n",
    "#             regu_user_bias += user_bias[key] ** 2\n",
    "#         for key in business_bias:\n",
    "#             regu_business_bias += business_bias[key] ** 2\n",
    "#         error += lam * (sum(q ** 2) + sum(p ** 2) + regu_user_bias + regu_business_bias)\n",
    "#         fig[num] = error        \n",
    "\n",
    "#     # examine: plot the graph \n",
    "#     plt.plot(range(0, ite), fig)\n",
    "#     plt.show()            \n",
    "#     print error             \n",
    "#     print \"done\"\n",
    "    return q, p, user_bias, business_bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Objective:\n",
    "## 1. Sochastic Gradient Decent testing function with bias\n",
    "\n",
    "## SGD testing function with baseline interface\n",
    "## input(7):\n",
    "#    file_name: testing file\n",
    "#    q and p: learned latend factor model\n",
    "#    user_match & business_match\n",
    "#    user_bias & business_bias: learned bias\n",
    "#    average\n",
    "## output(1):\n",
    "#    RMSE\n",
    "def SGD_test(file_name, q, p, user_match, business_match, user_bias, business_bias, average):\n",
    "    extrapolate_star = []\n",
    "    origin_star = []\n",
    "    size = 0\n",
    "    RMSE = 0\n",
    "    with open(file_name) as f:\n",
    "        for line in f:\n",
    "            temp = json.loads(line)\n",
    "            cur_user_id = temp[\"user_id\"]\n",
    "            cur_business_id = temp[\"business_id\"]\n",
    "            # check if current review is in the Matrix\n",
    "            if cur_user_id in user_match and cur_business_id in business_match:\n",
    "                size += 1\n",
    "                i = user_match[cur_user_id]\n",
    "                j = business_match[cur_business_id]\n",
    "                star = temp[\"stars\"]\n",
    "                b_x = user_bias[cur_user_id]\n",
    "                b_i = business_bias[cur_business_id] \n",
    "                RMSE += (star - (average + b_x + b_i + dot(q[i, ], p[j, ]))) ** 2\n",
    "        RMSE = sqrt(RMSE / float(size))    \n",
    "    return RMSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7\n",
      "1.06317357593\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX4AAAD8CAYAAABw1c+bAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAADxNJREFUeJzt222MXGd9hvHrbtYpeQFM621JbVOnagq4ETRmRV1okdXw\nwUmBVP0UVxARVbKQUkgQpeJFasTHShGCqFUiC0yaEjkqkEpRZRVoSTBUJGWdmLCJAZlQ8BqnXpqS\nUCI1Cfz7YU7Qstn1jHdmPLt9rp90pD3P88yceyfrO2fOmUlVIUlqxy9MOoAk6eyy+CWpMRa/JDXG\n4pekxlj8ktQYi1+SGmPxS1JjLH5JaozFL0mNmeq3IMl+4E3Aqaq6dJn5VwCfAHYAH6yqm7rxrcDt\nwK8CBeyrqo8OEmrTpk21bdu2QX8HSWre4cOHf1BV04Os7Vv8wG3A39Ar8eU8DrwL+OMl488C76mq\nB5K8EDic5PNV9Ui/A27bto3Z2dkBokmSAJJ8d9C1fS/1VNUheuW+0vypqvoq8MyS8ZNV9UD384+A\no8DmQYNJksbjrFzjT7INuAy4/zRr9iaZTTK7sLBwNmJJUpPGXvxJLgQ+A9xQVU+utK6q9lXVTFXN\nTE8PdJlKkrQKYy3+JBvolf4dVXXXOI8lSRrM2Io/SYCPA0er6sPjOo4k6cwM8nHOA8AuYFOSeeBG\nYANAVd2a5KXALPAi4KdJbgC2A68C3gZ8PcmR7uk+UFUHR/5bSJIG1rf4q2pPn/nHgC3LTH0ZyCpz\nSZLGxG/uSlJjLH5JaozFL0mNsfglqTEWvyQ1xuKXpMZY/JLUGItfkhpj8UtSYyx+SWqMxS9JjbH4\nJakxFr8kNcbil6TGWPyS1BiLX5IaY/FLUmMsfklqjMUvSY2x+CWpMRa/JDXG4pekxlj8ktQYi1+S\nGmPxS1JjLH5JaozFL0mNsfglqTF9iz/J/iSnksytMP+KJF9J8r9J/mLJ3O4k30xyLMn7RhVakrR6\ng5zx3wbsPs3848C7gJsWDyY5B/hb4ApgO7AnyfbVxZQkjUrf4q+qQ/TKfaX5U1X1VeCZJVOvBY5V\n1aNV9TRwJ3DVMGElScMb5zX+zcDxRfvz3ZgkaYLWzM3dJHuTzCaZXVhYmHQcSfp/a5zFfwLYumh/\nSze2rKraV1UzVTUzPT09xliS1LZxFv9XgUuSXJzkXOBq4O4xHk+SNICpfguSHAB2AZuSzAM3AhsA\nqurWJC8FZoEXAT9NcgOwvaqeTPLnwGeBc4D9VfXweH4NSdKg+hZ/Ve3pM/8Yvcs4y80dBA6uLpok\naRzWzM1dSdLZYfFLUmMsfklqjMUvSY2x+CWpMRa/JDXG4pekxlj8ktQYi1+SGmPxS1JjLH5JaozF\nL0mNsfglqTEWvyQ1xuKXpMZY/JLUGItfkhpj8UtSYyx+SWqMxS9JjbH4JakxFr8kNcbil6TGWPyS\n1BiLX5IaY/FLUmMsfklqjMUvSY3pW/xJ9ic5lWRuhfkkuTnJsSQPJdmxaO7dSR5OMpfkQJIXjDK8\nJOnMDXLGfxuw+zTzVwCXdNte4BaAJJuBdwEzVXUpcA5w9TBhJUnD61v8VXUIePw0S64Cbq+e+4CN\nSS7q5qaA85JMAecD3x82sCRpOKO4xr8ZOL5ofx7YXFUngJuA7wEngSeq6nMjOJ4kaQhju7mb5CX0\n3g1cDPwacEGSt55m/d4ks0lmFxYWxhVLkpo3iuI/AWxdtL+lG3sj8J2qWqiqZ4C7gNet9CRVta+q\nZqpqZnp6egSxJEnLGUXx3w1c0326Zye9Szon6V3i2Znk/CQBLgeOjuB4kqQhTPVbkOQAsAvYlGQe\nuBHYAFBVtwIHgSuBY8BTwLXd3P1JPg08ADwLPAjsG/2vIEk6E6mqSWd4npmZmZqdnZ10DElaN5Ic\nrqqZQdb6zV1JaozFL0mNsfglqTEWvyQ1xuKXpMZY/JLUGItfkhpj8UtSYyx+SWqMxS9JjbH4Jakx\nFr8kNcbil6TGWPyS1BiLX5IaY/FLUmMsfklqjMUvSY2x+CWpMRa/JDXG4pekxlj8ktQYi1+SGmPx\nS1JjLH5JaozFL0mNsfglqTEWvyQ1pm/xJ9mf5FSSuRXmk+TmJMeSPJRkx6K5jUk+neQbSY4m+b1R\nhpcknblBzvhvA3afZv4K4JJu2wvcsmjuo8A/V9UrgFcDR1cXU5I0KlP9FlTVoSTbTrPkKuD2qirg\nvu4s/yLgKeANwNu753kaeHrYwJKk4YziGv9m4Pii/flu7GJgAfhEkgeTfCzJBSM4niRpCOO8uTsF\n7ABuqarLgB8D71tpcZK9SWaTzC4sLIwxliS1bRTFfwLYumh/Szc2D8xX1f3d+Kfp/Y9gWVW1r6pm\nqmpmenp6BLEkScsZRfHfDVzTfbpnJ/BEVZ2sqseA40le3q27HHhkBMeTJA2h783dJAeAXcCmJPPA\njcAGgKq6FTgIXAkco3dD99pFD38ncEeSc4FHl8xJkiZgkE/17OkzX8B1K8wdAWZWF02SNA5+c1eS\nGmPxS1JjLH5JaozFL0mNsfglqTEWvyQ1xuKXpMZY/JLUGItfkhpj8UtSYyx+SWqMxS9JjbH4Jakx\nFr8kNcbil6TGWPyS1BiLX5IaY/FLUmMsfklqjMUvSY2x+CWpMRa/JDXG4pekxlj8ktQYi1+SGmPx\nS1JjLH5JaozFL0mNsfglqTF9iz/J/iSnksytMJ8kNyc5luShJDuWzJ+T5MEk/zSq0JKk1RvkjP82\nYPdp5q8ALum2vcAtS+avB46uJpwkafT6Fn9VHQIeP82Sq4Dbq+c+YGOSiwCSbAH+CPjYKMJKkoY3\nimv8m4Hji/bnuzGAjwB/Cfy035Mk2ZtkNsnswsLCCGJJkpYztpu7Sd4EnKqqw4Osr6p9VTVTVTPT\n09PjiiVJzRtF8Z8Ati7a39KNvR54S5L/AO4E/jDJJ0dwPEnSEEZR/HcD13Sf7tkJPFFVJ6vq/VW1\npaq2AVcDX6iqt47geJKkIUz1W5DkALAL2JRkHrgR2ABQVbcCB4ErgWPAU8C14worSRpe3+Kvqj19\n5gu4rs+ae4F7zySYJGk8/OauJDXG4pekxlj8ktQYi1+SGmPxS1JjLH5JaozFL0mNsfglqTEWvyQ1\nxuKXpMZY/JLUGItfkhpj8UtSYyx+SWqMxS9JjbH4JakxFr8kNcbil6TGWPyS1BiLX5IaY/FLUmMs\nfklqjMUvSY2x+CWpMRa/JDXG4pekxlj8ktQYi1+SGtO3+JPsT3IqydwK80lyc5JjSR5KsqMb35rk\nniSPJHk4yfWjDi9JOnODnPHfBuw+zfwVwCXdthe4pRt/FnhPVW0HdgLXJdm++qiSpFHoW/xVdQh4\n/DRLrgJur577gI1JLqqqk1X1QPccPwKOAptHEVqStHqjuMa/GTi+aH+eJQWfZBtwGXD/Sk+SZG+S\n2SSzCwsLI4glSVrO2G/uJrkQ+AxwQ1U9udK6qtpXVTNVNTM9PT3uWJLUrFEU/wlg66L9Ld0YSTbQ\nK/07ququERxLkjSkURT/3cA13ad7dgJPVNXJJAE+Dhytqg+P4DiSpBGY6rcgyQFgF7ApyTxwI7AB\noKpuBQ4CVwLHgKeAa7uHvh54G/D1JEe6sQ9U1cFR/gKSpDPTt/irak+f+QKuW2b8y0BWH02SNA5+\nc1eSGmPxS1JjLH5JaozFL0mNsfglqTEWvyQ1xuKXpMZY/JLUGItfkhpj8UtSYyx+SWqMxS9JjbH4\nJakxFr8kNcbil6TGWPyS1BiLX5IaY/FLUmMsfklqjMUvSY2x+CWpMRa/JDXG4pekxqSqJp3heZIs\nAN+ddI4lNgE/mHSIAZl1fNZT3vWUFdZX3rWY9deranqQhWuy+NeiJLNVNTPpHIMw6/isp7zrKSus\nr7zrKetyvNQjSY2x+CWpMRb/4PZNOsAZMOv4rKe86ykrrK+86ynr83iNX5Ia4xm/JDWm+eJPsjvJ\nN5McS/K+FdbsSnIkycNJvtiNvbwbe257MskNazFrN/7ubmwuyYEkLxhn1hHkvb7L+vC4X9dBsiZ5\n76L/1nNJfpLklwZ57BrMuz/JqSRzazlrkq1J7knySPd3cP0az/uCJP+e5Gtd3g+djbyrUlXNbsA5\nwLeB3wDOBb4GbF+yZiPwCPCybv9XVniex+h9jnbNZQU2A98Bzuv2/wF4+1p9bYFLgTngfGAK+Bfg\nNyeZdcn6NwNfWM1jJ523238DsAOYG2fOEby2FwE7up9fCHxrLb+2QIALu583APcDO8f9Gq9ma/2M\n/7XAsap6tKqeBu4Erlqy5k+Bu6rqewBVdWqZ57kc+HZVjfNLZ8NmnQLOSzJFr1C/P8asw+Z9JXB/\nVT1VVc8CXwT+ZMJZF9sDHFjlY0dhmLxU1SHg8fFG/JlVZ62qk1X1QPfzj4Cj9E5i1mreqqr/6cY3\ndNuavInaevFvBo4v2p/n+X9YvwW8JMm9SQ4nuWaZ57maRf+wxmTVWavqBHAT8D3gJPBEVX1ureal\nd7b/B0l+Ocn5wJXA1glnBaDLsxv4zJk+doSGyXu2jSRrkm3AZfTOosdpqLxJzklyBDgFfL6qxp13\nVaYmHWAdmAJeQ++s/jzgK0nuq6pvASQ5F3gL8P7JRfyZZbMCC/TOWi4Gfgh8Kslbq+qTE0vas9Jr\nezTJXwOfA34MHAF+MrmYP+fNwL9V1dk6Yx7Wesq7bNYkF9Ir1xuq6smJJFve8/JW1U+A30myEfjH\nJJdW1Vm5l3ImWj/jP8HPn0lu6cYWmwc+W1U/rqofAIeAVy+avwJ4oKr+c6xJh8v6RuA7VbVQVc8A\ndwGvW8N5qaqPV9VrquoNwH/Tu747yazPWfru7kweOyrD5D3bhsqaZAO90r+jqu4aS8KfN5LXtqp+\nCNxD7x3B2jPpmwyT3OidcT5K70z4uRs5v71kzSuBf+3Wnk/vMsSli+bvBK5dy1mB3wUe7sYC/B3w\nzrWat5t77kbvy4BvABsnmbVb92J618YvONPHrpW8i+a2cXZu7g7z2ga4HfjIuHOOKO/0c3+n9N7B\nfgl409nKfka/56QDTHqjd/34W/Tu5H+wG3sH8I5Fa95L79Mnc/Tebj43fgHwX8CL10HWD3UFOgf8\nPfCLazzvl7rxrwGXr5GsbwfuHOSxazzvAXr3ep6h967rz9ZiVuD36d0cfYje5b4jwJVr9bUFXgU8\n2OWdA/7qbPwtrGbzm7uS1JjWr/FLUnMsfklqjMUvSY2x+CWpMRa/JDXG4pekxlj8ktQYi1+SGvN/\nxAq9mPOy0kYAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x111787090>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n"
     ]
    }
   ],
   "source": [
    "## Tuning Prameter\n",
    "#    1. tune \"lam\"\n",
    "\n",
    "ite = 15                                  \n",
    "# lam = [(x + 1) / float(10) for x in range(3, 15)]\n",
    "lam = [0.7]\n",
    "mu = 0.005                                \n",
    "k = 20                                    \n",
    "m = user_id.__len__()                     \n",
    "n = business_id.__len__()        \n",
    "output = empty(lam.__len__())\n",
    "train_file = 'yelp_data/training_at5.json'\n",
    "test_file = 'yelp_data/testing_at5.json'\n",
    "\n",
    "for cur_lam in lam:\n",
    "    user_bias = dict(origin_user_bias)\n",
    "    business_bias = dict(origin_business_bias)\n",
    "    # training\n",
    "    [q, p, user_bias, business_bias] = SGD_train(\n",
    "        train_file, ite, cur_lam, mu, k, m, n, user_match, business_match, user_bias, business_bias, average)\n",
    "    # testing\n",
    "    RMSE = SGD_test(test_file, q, p, user_match, business_match, user_bias, business_bias, average)\n",
    "    output[lam.index(cur_lam)] = RMSE\n",
    "    print cur_lam\n",
    "    print RMSE\n",
    "\n",
    "plt.plot(lam, output)\n",
    "plt.show()                \n",
    "print \"done\"    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Aggregation the final results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n"
     ]
    }
   ],
   "source": [
    "## don't run this cell\n",
    "train_file = \"yelp_data/training_at5.json\"\n",
    "# construct & initialize the dictionary\n",
    "cluster = {}\n",
    "for user_key in user_id:\n",
    "    cluster[user_key] = {}\n",
    "    for business_key in business_id:\n",
    "        cluster[user_key][business_key] = 0\n",
    "\n",
    "# filling the dictionary\n",
    "for user_key in user_id:\n",
    "    for business_key in business_id:\n",
    "        i = user_match[user_key]\n",
    "        j = business_match[business_key]\n",
    "        b_x = user_bias[user_key]\n",
    "        b_i = business_bias[business_key]  \n",
    "        # assign the score\n",
    "        cluster[user_key][business_key] = average + b_x + b_i + dot(q[i, ], p[j, ])\n",
    "    \n",
    "print \"done\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "print cluster[\"MUsXhUuDRzGLkh2l3aNDGA\"][\"bxUZorggwGDpU_liCTZazw\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## objective: calculate each \"q, p, user_bias, business_bias, user_match, business_match\" within each cluster\n",
    "# read all files in the training file\n",
    "\n",
    "## \"cluster_data\" collects all latent factor & its corresponding data in a dectionary. Key is just number\n",
    "#    the data format is cluster_data[key] = [q, p, user_bias, business_bias, user_match, business_match]\n",
    "cluster_data = {}\n",
    "cluster_key = 0\n",
    "for filename in glob.glob('proj_data/*.json'):\n",
    "    # create a dictionary for cluster\n",
    "    cluster_data[cluster_key] = []\n",
    "\n",
    "    # get the user_id & business_id in a file\n",
    "    [user_id, business_id] = matrix_entry(filename)\n",
    "    # get the matching \n",
    "    [user_match, business_match] = matching(user_id, business_id)\n",
    "    # calculate its corresponding baseline\n",
    "    [average, origin_user_bias, origin_business_bias] = baseline(filename, user_id, business_id)\n",
    "    # SGD training \n",
    "    [q, p, user_bias, business_bias] = SGD_train(\n",
    "        filename, ite, cur_lam, mu, k, m, n, user_match, business_match, user_bias, business_bias, average)\n",
    "    \n",
    "    cluster_data[cluster_key].append(q)\n",
    "    cluster_data[cluster_key].append(p)\n",
    "    cluster_data[cluster_key].append(user_bias)\n",
    "    cluster_data[cluster_key].append(business_bias)\n",
    "    cluster_data[cluster_key].append(user_match)\n",
    "    cluster_data[cluster_key].append(business_match)\n",
    "    cluster_key += 1\n",
    "\n",
    "    \n",
    "print \"done\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Unterminated string starting at: line 1 column 150 (char 149)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-43-7bb9144449b1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[0mfile_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"proj_data/cluster9.json\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[0mcur_lam\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 34\u001b[0;31m \u001b[0msingle_cluster\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msingleCluster\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcur_lam\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     35\u001b[0m \u001b[0;32mprint\u001b[0m \u001b[0;34m\"done\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-43-7bb9144449b1>\u001b[0m in \u001b[0;36msingleCluster\u001b[0;34m(file_name, lam)\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0msingleCluster\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlam\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0;31m# get the user_id & business_id in a file\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0;34m[\u001b[0m\u001b[0muser_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbusiness_id\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmatrix_entry\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m     \u001b[0;31m# get the matching\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0;34m[\u001b[0m\u001b[0muser_match\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbusiness_match\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmatching\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0muser_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbusiness_id\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-2-a0302258b0fa>\u001b[0m in \u001b[0;36mmatrix_entry\u001b[0;34m(file_name)\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile_name\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mline\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m             \u001b[0mtemp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mjson\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloads\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mline\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m             \u001b[0muser_id\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtemp\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"user_id\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m             \u001b[0mbusiness_id\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtemp\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"business_id\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/ginolee/anaconda/lib/python2.7/json/__init__.pyc\u001b[0m in \u001b[0;36mloads\u001b[0;34m(s, encoding, cls, object_hook, parse_float, parse_int, parse_constant, object_pairs_hook, **kw)\u001b[0m\n\u001b[1;32m    337\u001b[0m             \u001b[0mparse_int\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mparse_float\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mNone\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    338\u001b[0m             parse_constant is None and object_pairs_hook is None and not kw):\n\u001b[0;32m--> 339\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_default_decoder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    340\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcls\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    341\u001b[0m         \u001b[0mcls\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mJSONDecoder\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/ginolee/anaconda/lib/python2.7/json/decoder.pyc\u001b[0m in \u001b[0;36mdecode\u001b[0;34m(self, s, _w)\u001b[0m\n\u001b[1;32m    362\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    363\u001b[0m         \"\"\"\n\u001b[0;32m--> 364\u001b[0;31m         \u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraw_decode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0midx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0m_w\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    365\u001b[0m         \u001b[0mend\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_w\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    366\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mend\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/ginolee/anaconda/lib/python2.7/json/decoder.pyc\u001b[0m in \u001b[0;36mraw_decode\u001b[0;34m(self, s, idx)\u001b[0m\n\u001b[1;32m    378\u001b[0m         \"\"\"\n\u001b[1;32m    379\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 380\u001b[0;31m             \u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscan_once\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0midx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    381\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    382\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"No JSON object could be decoded\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Unterminated string starting at: line 1 column 150 (char 149)"
     ]
    }
   ],
   "source": [
    "## single cluster creation\n",
    "def singleCluster(file_name, lam):\n",
    "    # get the user_id & business_id in a file\n",
    "    [user_id, business_id] = matrix_entry(file_name)\n",
    "    # get the matching \n",
    "    [user_match, business_match] = matching(user_id, business_id)\n",
    "    # calculate its corresponding baseline\n",
    "    [average, user_bias, business_bias] = baseline(file_name, user_id, business_id)\n",
    "    \n",
    "    # set the parameter\n",
    "    ite = 15                                  \n",
    "    mu = 0.005                                \n",
    "    k = 20                                    \n",
    "    m = user_id.__len__()                     \n",
    "    n = business_id.__len__()  \n",
    "    \n",
    "    # SGD training \n",
    "    [q, p, user_bias, business_bias] = SGD_train(\n",
    "        file_name, ite, lam, mu, k, m, n, user_match, business_match, user_bias, business_bias, average)\n",
    "    # current cluster\n",
    "    cur_cluster = []\n",
    "    cur_cluster.append(q)\n",
    "    cur_cluster.append(p)\n",
    "    cur_cluster.append(user_bias)\n",
    "    cur_cluster.append(business_bias)\n",
    "    cur_cluster.append(user_match)\n",
    "    cur_cluster.append(business_match)\n",
    "    return cur_cluster\n",
    "    \n",
    "# implement the method\n",
    "# file_name = 'yelp_data/training_at5.json'\n",
    "file_name = \"proj_data/cluster9.json\"\n",
    "cur_lam = 0.2\n",
    "single_cluster = singleCluster(file_name, cur_lam)\n",
    "print \"done\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "done\n"
     ]
    }
   ],
   "source": [
    "## multiple clusters\n",
    "def multiCluster(directory):\n",
    "    cluster_data = {}\n",
    "    cluster_key = 0\n",
    "    for file_name in glob.glob(directory):\n",
    "        print cluster_key\n",
    "        # create a dictionary for cluster\n",
    "        cur_lam = 0.2\n",
    "        cluster_data[cluster_key] = clusterInfor(file_name, cur_lam)\n",
    "        cluster_key += 1\n",
    "    return cluster_data\n",
    "\n",
    "directory = 'proj_data/*.json'\n",
    "all_cluster = multiCluster(directory)\n",
    "print \"done\"        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def aggregationTest(file_name, cluster):\n",
    "    size = 0\n",
    "    RMSE = 0\n",
    "    with open(file_name) as f:\n",
    "        for line in f:\n",
    "            temp = json.loads(line)\n",
    "            cur_user_id = temp[\"user_id\"]\n",
    "            cur_business_id = temp[\"business_id\"]\n",
    "\n",
    "            m=0\n",
    "            num=0\n",
    "            if cur_user_id in cluster[1][4] and cur_business_id in cluster[1][5]:\n",
    "                size += 1\n",
    "\n",
    "                for x in range(0,9):\n",
    "                    if cur_user_id in cluster[x][4] and cur_business_id in cluster[x][5]:\n",
    "                        num+=1\n",
    "\n",
    "                        i = cluster[x][4][cur_user_id]\n",
    "                        j = cluster[x][5][cur_business_id]\n",
    "\n",
    "                        star = temp[\"stars\"]\n",
    "\n",
    "                        b_x = cluster[x][2][cur_user_id]\n",
    "                        b_i = cluster[x][3][cur_business_id] \n",
    "                        m+=(average + b_x + b_i + dot(cluster[x][0][i, ], cluster[x][1][j, ]))\n",
    "                score=m/num\n",
    "\n",
    "                RMSE += (star - score) ** 2\n",
    "        RMSE = sqrt(RMSE / float(size))    \n",
    "    return RMSE\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Final Test: RMSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Test Rest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Comparison\n",
    "1. Global Average\n",
    "2. Plus Bias \n",
    "3. Latent Factor\n",
    "4. Latent Factor with bias\n",
    "5. Cluster & Aggregation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
