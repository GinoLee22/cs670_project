{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from nltk.stem.porter import PorterStemmer\n",
    "import json\n",
    "import re\n",
    "import glob\n",
    "import math\n",
    "from numpy import *\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Pre-Process (Zhong)\n",
    "Delete the users and restaurants with few comments to avoid \"Cold-Start Problem\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Process (Wang)\n",
    "Cluster the pre-processed data using word2vec"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Latent Factors + Bias\n",
    "Using Latent Factor Model + User and Item bias to obtain \"user-concept\" and \"item-concept\" Matrices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "IOError",
     "evalue": "[Errno 2] No such file or directory: 'yelp_data/training_at5.json'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIOError\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-a0302258b0fa>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0mfile_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'yelp_data/training_at5.json'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m \u001b[0;34m[\u001b[0m\u001b[0muser_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbusiness_id\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmatrix_entry\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m \u001b[0;32mprint\u001b[0m \u001b[0muser_id\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__len__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0;32mprint\u001b[0m \u001b[0mbusiness_id\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__len__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-2-a0302258b0fa>\u001b[0m in \u001b[0;36mmatrix_entry\u001b[0;34m(file_name)\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0muser_id\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0mbusiness_id\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m     \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile_name\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mline\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m             \u001b[0mtemp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mjson\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloads\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mline\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIOError\u001b[0m: [Errno 2] No such file or directory: 'yelp_data/training_at5.json'"
     ]
    }
   ],
   "source": [
    "## objectives\n",
    "## 1. get the number of users & items in training data. Entry of matrix\n",
    "\n",
    "## interface:\n",
    "## input(1)\n",
    "#    name of a file\n",
    "## output(2)\n",
    "#    user_id: a list of distinct users\n",
    "#    business_id: a list of distinct restaurant\n",
    "\n",
    "def matrix_entry(file_name):\n",
    "    # get the size of user_id & business_id\n",
    "    user_id = []\n",
    "    business_id = []\n",
    "    with open(file_name) as f:\n",
    "        for line in f:\n",
    "            temp = json.loads(line)        \n",
    "            user_id.append(temp[\"user_id\"])\n",
    "            business_id.append(temp[\"business_id\"])\n",
    "    # This is without duplication: set\n",
    "    user_id = list(set(user_id))\n",
    "    business_id = list(set(business_id))\n",
    "    return [user_id, business_id]\n",
    "\n",
    "file_name = 'yelp_data/training_at5.json'\n",
    "[user_id, business_id] = matrix_entry(file_name)\n",
    "print user_id.__len__()\n",
    "print business_id.__len__()\n",
    "print \"done\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n"
     ]
    }
   ],
   "source": [
    "## Objectives\n",
    "## 1. calculate the \"Global Average\" with variable name \"average\"\n",
    "## 2. user bias of all users with variable name \"origin_user_bias\"\n",
    "#     it is a dictionary = {user_id --> user average score}\n",
    "#     intermedia variable: user_bias_list = {user_id --> a list of scores}\n",
    "## 3. restaurant bias of all restaurants with variable name \"origin_restaurant_bias\"\n",
    "#     it is a dictionary = {business_id --> restaurant averate score}\n",
    "#     intermedia variable: business_bias_list = {business_id --> a list of scores}\n",
    "\n",
    "## interface:\n",
    "## input(3:\n",
    "#    name of a file\n",
    "#    user_id\n",
    "#    business_id\n",
    "#\n",
    "## output(3):\n",
    "#    global average\n",
    "#    origin_user_bias\n",
    "#    origin_business_bias\n",
    "def baseline(file_name, user_id, business_id):\n",
    "    average = 0\n",
    "    num_star = 0\n",
    "    user_bias_list = {}\n",
    "    origin_user_bias = {}\n",
    "    business_bias_list = {}\n",
    "    origin_business_bias = {}\n",
    "    for value in user_id:\n",
    "        user_bias_list[value] = []\n",
    "        origin_user_bias[value] = 0\n",
    "    for value in business_id:\n",
    "        business_bias_list[value] = []\n",
    "        origin_business_bias[value] = 0\n",
    "\n",
    "    # adding the list\n",
    "    with open(file_name) as f:\n",
    "        for line in f:\n",
    "            # get the infor from file\n",
    "            temp = json.loads(line)        \n",
    "            cur_user_id = temp[\"user_id\"]\n",
    "            cur_business_id = temp[\"business_id\"]\n",
    "            star = temp[\"stars\"]\n",
    "            # filling the dictionary & calculate the average\n",
    "            average += star\n",
    "            num_star += 1\n",
    "            user_bias_list[cur_user_id].append(star)\n",
    "            business_bias_list[cur_business_id].append(star)\n",
    "\n",
    "    # average\n",
    "    average /= float(num_star)\n",
    "    # calculate: user_bias = {user_id --> average score} & business_bias = {business_id --> average score}\n",
    "    for user_key in user_bias_list:\n",
    "        b_x = sum(user_bias_list[user_key]) / float(user_bias_list[user_key].__len__()) - average\n",
    "        origin_user_bias[user_key] = b_x\n",
    "    for business_key in business_bias_list:\n",
    "        b_i = sum(business_bias_list[business_key]) / float(business_bias_list[business_key].__len__()) - average\n",
    "        origin_business_bias[business_key] = b_i\n",
    "    return [average, origin_user_bias, origin_business_bias]\n",
    "\n",
    "file_name = 'yelp_data/training_at5.json'\n",
    "[average, origin_user_bias, origin_business_bias] = baseline(file_name, user_id, business_id)\n",
    "print \"done\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n"
     ]
    }
   ],
   "source": [
    "## Objective:\n",
    "## 1. Make \"user_id\" and \"business_id\" in the data match the index in latent factor model\n",
    "\n",
    "## interface\n",
    "## input():\n",
    "#    user_id\n",
    "#   business_id\n",
    "## output():\n",
    "#    \n",
    "def matching(user_id, business_id):\n",
    "    # user_id = list(user_id)\n",
    "    user_idx = range(user_id.__len__())\n",
    "    user_match = dict(zip(user_id, user_idx))\n",
    "\n",
    "#     business_id = list(business_id)\n",
    "    business_idx = range(business_id.__len__())\n",
    "    business_match= dict(zip(business_id, business_idx))\n",
    "    return [user_match, business_match]\n",
    "\n",
    "[user_match, business_match] = matching(user_id, business_id)\n",
    "print \"done\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Objective:\n",
    "## 1. Sochastic Gradient Decent training function with bias\n",
    "\n",
    "## SGD training function interface\n",
    "## inputs(10):\n",
    "#    file_name: training file\n",
    "#    ite: number of iteration\n",
    "#    lam: regulation factor: assume lam1 == lam2 == lam3 == lam4\n",
    "#    mu: study rate: assume mu1 = mu2\n",
    "#    k: number of concept in latent factor\n",
    "#    m: number of users\n",
    "#    n: number of items (restaurant)\n",
    "#    user_match: from user_id to index i\n",
    "#    business_match: from business_id to index j\n",
    "#    user_bias & business_bias: should equal to \"original user_bias & business_bias\", whose values won't change\n",
    "#    average: global average\n",
    "## outputs(4):\n",
    "#    latent factor q & p, updated user_bias & business_bias\n",
    "\n",
    "def SGD_train(file_name, ite, lam, mu, k, m, n, user_match, business_match, user_bias, business_bias, average):\n",
    "    # initialization\n",
    "    q = np.random.rand(m, k) * sqrt(5.0 / k)  # normalization\n",
    "    p = np.random.rand(n, k) * sqrt(5.0 / k)\n",
    "    fig = empty(ite)\n",
    "\n",
    "    ## essential steps\n",
    "    # 1. read the file to get user_id, business_id, stars\n",
    "    # 2. find the corresponding index of user_id, business_id in q and p\n",
    "    # 3. Stochastic GD alg\n",
    "    for num in range(0, ite):\n",
    "#         print num\n",
    "        # read the file to update q & p\n",
    "        with open(file_name) as f:\n",
    "            for line in f:\n",
    "                temp = json.loads(line)\n",
    "                cur_user_id = temp[\"user_id\"]\n",
    "                cur_business_id = temp[\"business_id\"]\n",
    "                # get initialized b_x, b_i\n",
    "                b_x = user_bias[cur_user_id]\n",
    "                b_i = business_bias[cur_business_id]\n",
    "                i = user_match[cur_user_id]                  # get the index of corresponding user in q\n",
    "                j = business_match[cur_business_id]          # get the index of corresponding business in p\n",
    "                star = temp[\"stars\"]\n",
    "                # updating p, q, b_x & b_i\n",
    "                eps = 2 * (star - (average + b_x + b_i + dot(q[i, ], p[j, ])))\n",
    "                temp_q = q[i, ] + mu * (eps * p[j, ] - 2 * lam * q[i, ])\n",
    "                temp_p = p[j, ] + mu * (eps * q[i, ] - 2 * lam * p[j, ])\n",
    "                q[i, ] = temp_q\n",
    "                p[j, ] = temp_p\n",
    "                user_bias[cur_user_id] = b_x + mu * (eps - 2 * lam * b_x)\n",
    "                business_bias[cur_business_id] = b_i + mu * (eps - 2 * lam * b_i)\n",
    "    \n",
    "        # read the file to calculate the error\n",
    "#         error = 0\n",
    "#         with open(file_name) as f:\n",
    "#             for line in f:\n",
    "#                 temp = json.loads(line)\n",
    "#                 cur_user_id = temp[\"user_id\"]\n",
    "#                 cur_business_id = temp[\"business_id\"]\n",
    "#                 i = user_match[cur_user_id]\n",
    "#                 j = business_match[cur_business_id]\n",
    "#                 b_x = user_bias[cur_user_id]\n",
    "#                 b_i = business_bias[cur_business_id] \n",
    "#                 star = temp[\"stars\"]\n",
    "#                 error += (star - (average + b_x + b_i + dot(q[i, ], p[j, ]))) ** 2\n",
    "#         # add the regulation error (combine them in all)\n",
    "#         # regulation for b_x & b_i\n",
    "#         regu_user_bias = 0\n",
    "#         regu_business_bias = 0\n",
    "#         for key in user_bias:\n",
    "#             regu_user_bias += user_bias[key] ** 2\n",
    "#         for key in business_bias:\n",
    "#             regu_business_bias += business_bias[key] ** 2\n",
    "#         error += lam * (sum(q ** 2) + sum(p ** 2) + regu_user_bias + regu_business_bias)\n",
    "#         fig[num] = error        \n",
    "\n",
    "#     # examine: plot the graph \n",
    "#     plt.plot(range(0, ite), fig)\n",
    "#     plt.show()            \n",
    "#     print error             \n",
    "#     print \"done\"\n",
    "    return q, p, user_bias, business_bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Objective:\n",
    "## 1. Sochastic Gradient Decent testing function with bias\n",
    "\n",
    "## SGD testing function with baseline interface\n",
    "## input(7):\n",
    "#    file_name: testing file\n",
    "#    q and p: learned latend factor model\n",
    "#    user_match & business_match\n",
    "#    user_bias & business_bias: learned bias\n",
    "#    average\n",
    "## output(1):\n",
    "#    RMSE\n",
    "def SGD_test(file_name, q, p, user_match, business_match, user_bias, business_bias, average):\n",
    "    extrapolate_star = []\n",
    "    origin_star = []\n",
    "    size = 0\n",
    "    RMSE = 0\n",
    "    with open(file_name) as f:\n",
    "        for line in f:\n",
    "            temp = json.loads(line)\n",
    "            cur_user_id = temp[\"user_id\"]\n",
    "            cur_business_id = temp[\"business_id\"]\n",
    "            # check if current review is in the Matrix\n",
    "            if cur_user_id in user_match and cur_business_id in business_match:\n",
    "                size += 1\n",
    "                i = user_match[cur_user_id]\n",
    "                j = business_match[cur_business_id]\n",
    "                star = temp[\"stars\"]\n",
    "                b_x = user_bias[cur_user_id]\n",
    "                b_i = business_bias[cur_business_id] \n",
    "                RMSE += (star - (average + b_x + b_i + dot(q[i, ], p[j, ]))) ** 2\n",
    "        RMSE = sqrt(RMSE / float(size))    \n",
    "    return RMSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7\n",
      "1.06349497243\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX4AAAD8CAYAAABw1c+bAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n5ky9mBsjVTwAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x104d31ad0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n"
     ]
    }
   ],
   "source": [
    "## Tuning Prameter\n",
    "#    1. tune \"lam\"\n",
    "\n",
    "ite = 15                                  \n",
    "# lam = [(x + 1) / float(10) for x in range(3, 15)]\n",
    "lam = [0.7]\n",
    "mu = 0.005                                \n",
    "k = 20                                    \n",
    "m = user_id.__len__()                     \n",
    "n = business_id.__len__()        \n",
    "output = empty(lam.__len__())\n",
    "train_file = 'yelp_data/training_at5.json'\n",
    "test_file = 'yelp_data/testing_at5.json'\n",
    "\n",
    "for cur_lam in lam:\n",
    "    user_bias = dict(origin_user_bias)\n",
    "    business_bias = dict(origin_business_bias)\n",
    "    # training\n",
    "    [q, p, user_bias, business_bias] = SGD_train(\n",
    "        train_file, ite, cur_lam, mu, k, m, n, user_match, business_match, user_bias, business_bias, average)\n",
    "    # testing\n",
    "    RMSE = SGD_test(test_file, q, p, user_match, business_match, user_bias, business_bias, average)\n",
    "    output[lam.index(cur_lam)] = RMSE\n",
    "    print cur_lam\n",
    "    print RMSE\n",
    "\n",
    "plt.plot(lam, output)\n",
    "plt.show()                \n",
    "print \"done\"    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Aggregation the final results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## objective: calculate each \"q, p, user_bias, business_bias, user_match, business_match\" within each cluster\n",
    "# read all files in the training file\n",
    "\n",
    "## \"cluster_data\" collects all latent factor & its corresponding data in a dectionary. Key is just number\n",
    "#    the data format is cluster_data[key] = [q, p, user_bias, business_bias, user_match, business_match]\n",
    "cluster_data = {}\n",
    "cluster_key = 0\n",
    "for filename in glob.glob('proj_data/*.json'):\n",
    "    # create a dictionary for cluster\n",
    "    cluster_data[cluster_key] = []\n",
    "\n",
    "    # get the user_id & business_id in a file\n",
    "    [user_id, business_id] = matrix_entry(filename)\n",
    "    # get the matching \n",
    "    [user_match, business_match] = matching(user_id, business_id)\n",
    "    # calculate its corresponding baseline\n",
    "    [average, origin_user_bias, origin_business_bias] = baseline(filename, user_id, business_id)\n",
    "    # SGD training \n",
    "    [q, p, user_bias, business_bias] = SGD_train(\n",
    "        filename, ite, cur_lam, mu, k, m, n, user_match, business_match, user_bias, business_bias, average)\n",
    "    \n",
    "    cluster_data[cluster_key].append(q)\n",
    "    cluster_data[cluster_key].append(p)\n",
    "    cluster_data[cluster_key].append(user_bias)\n",
    "    cluster_data[cluster_key].append(business_bias)\n",
    "    cluster_data[cluster_key].append(user_match)\n",
    "    cluster_data[cluster_key].append(business_match)\n",
    "    cluster_key += 1\n",
    "\n",
    "    \n",
    "print \"done\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Final Test: RMSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Test Rest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Comparison\n",
    "1. Global Average\n",
    "2. Plus Bias \n",
    "3. Latent Factor\n",
    "4. Latent Factor with bias\n",
    "5. Cluster & Aggregation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
